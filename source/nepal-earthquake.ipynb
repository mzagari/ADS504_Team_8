{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5735aab7",
   "metadata": {},
   "source": [
    "# Nepal Earthquake - Structural Risk Prediction\n",
    "__Martin Zagari, Summer Purcschke, and Dave Friesen - ADS-504-01-SU22__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab62c01d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'Martin Zagari, Summer Purschke, Dave Friesen'\n",
    "__email__ = 'mzagari@sandiego.edu, spurschke@sandiego.edu, dfriesen@sandiego.edu'\n",
    "__version__ = '1.0'\n",
    "__date__ = 'August 2022'\n",
    "__license__ = 'MIT'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4d0c3a",
   "metadata": {},
   "source": [
    "### Problem Statement: *[. . .]*  \n",
    "\n",
    "### Hypothesis: *[. . .]*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f6cd85",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "d5fac32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modeling\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "# Utilities\n",
    "import joblib\n",
    "import re\n",
    "from time import time\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "#warnings.resetwarnings()\n",
    "\n",
    "# Set basic options for consistent output\n",
    "PRECISION = 2\n",
    "np.set_printoptions(precision = PRECISION)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "pd.set_option('display.precision', PRECISION)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "\n",
    "# Set Matplotlib defaults for consistent visualization look 'n' feel\n",
    "FONTSIZE_S = 10\n",
    "FONTSIZE_M = 12\n",
    "FONTSIZE_L = 14\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.titlesize'] = FONTSIZE_L\n",
    "plt.rcParams['figure.figsize'] = (7, 7 / (16 / 9))\n",
    "plt.rcParams['figure.subplot.left'] = '0.1'\n",
    "plt.rcParams['figure.subplot.bottom'] = '0.1'\n",
    "plt.rcParams['figure.subplot.top'] = '0.9'\n",
    "plt.rcParams['figure.subplot.wspace'] = '0.4'\n",
    "plt.rcParams['lines.linewidth'] = '2'\n",
    "plt.rcParams['axes.linewidth'] = '2'\n",
    "plt.rcParams['axes.titlesize'] = '8'\n",
    "#plt.rcParams['axes.titleweight'] = 'bold'\n",
    "plt.rcParams['axes.labelsize'] = FONTSIZE_M\n",
    "plt.rcParams['xtick.labelsize'] = FONTSIZE_S\n",
    "plt.rcParams['ytick.labelsize'] = FONTSIZE\n",
    "plt.rcParams['grid.linewidth'] = '1'\n",
    "plt.rcParams['legend.fontsize'] = FONTSIZE_S\n",
    "plt.rcParams['legend.title_fontsize'] = FONTSIZE_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "422d535b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/davidfriesen/Library/CloudStorage/OneDrive-Personal/projects/ADS504_Team_8/data\n"
     ]
    }
   ],
   "source": [
    "# Set working directory (depending on coder)\n",
    "%cd '/Users/davidfriesen/Desktop/OneDrive/projects/ADS504_Team_8/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab16b7d0",
   "metadata": {},
   "source": [
    "## Data Load, Validation, and Structure Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0fab09c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structure: file=737695, import=737694, delta=1\n",
      "Ownership: file=762106, import=762105, delta=1\n",
      "Damage: file=652689, import=652687, delta=2\n"
     ]
    }
   ],
   "source": [
    "# Set row count control totals\n",
    "structure_ctrl = sum(1 for line in open('csv_building_structure.csv'))\n",
    "ownership_ctrl = sum(1 for line in open('csv_building_ownership_and_use.csv'))\n",
    "damage_ctrl = sum(1 for line in open('csv_building_damage_assessment_featex.csv'))\n",
    "\n",
    "# Read files, accomodating any 'bad' rows\n",
    "structure_df = pd.read_csv('csv_building_structure.csv', on_bad_lines = 'skip', low_memory = False)\n",
    "ownership_df = pd.read_csv('csv_building_ownership_and_use.csv', on_bad_lines = 'skip', low_memory = False)\n",
    "damage_df = pd.read_csv('csv_building_damage_assessment_featex.csv', on_bad_lines = 'skip', low_memory = False)\n",
    "\n",
    "# Confirm load counts\n",
    "print('Structure: file=%0d, import=%0d, delta=%0d' %\n",
    "      (structure_ctrl, len(structure_df), structure_ctrl - len(structure_df)))\n",
    "print('Ownership: file=%0d, import=%0d, delta=%0d' %\n",
    "      (ownership_ctrl, len(ownership_df), ownership_ctrl - len(ownership_df)))\n",
    "print('Damage: file=%0d, import=%0d, delta=%0d' %\n",
    "      (damage_ctrl, len(damage_df), damage_ctrl - len(damage_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a70e1af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 737694 entries, 0 to 737693\n",
      "Data columns (total 31 columns):\n",
      " #   Column                                  Non-Null Count   Dtype  \n",
      "---  ------                                  --------------   -----  \n",
      " 0   building_id                             737694 non-null  float64\n",
      " 1   district_id                             737694 non-null  int64  \n",
      " 2   vdcmun_id                               737694 non-null  int64  \n",
      " 3   ward_id                                 737694 non-null  int64  \n",
      " 4   count_floors_pre_eq                     737694 non-null  int64  \n",
      " 5   count_floors_post_eq                    737694 non-null  int64  \n",
      " 6   age_building                            737694 non-null  int64  \n",
      " 7   plinth_area_sq_ft                       737694 non-null  int64  \n",
      " 8   height_ft_pre_eq                        737694 non-null  int64  \n",
      " 9   height_ft_post_eq                       737694 non-null  int64  \n",
      " 10  land_surface_condition                  737694 non-null  object \n",
      " 11  foundation_type                         737694 non-null  object \n",
      " 12  roof_type                               737694 non-null  object \n",
      " 13  ground_floor_type                       737694 non-null  object \n",
      " 14  other_floor_type                        737694 non-null  object \n",
      " 15  position                                737693 non-null  object \n",
      " 16  plan_configuration                      737693 non-null  object \n",
      " 17  has_superstructure_adobe_mud            737694 non-null  int64  \n",
      " 18  has_superstructure_mud_mortar_stone     737694 non-null  int64  \n",
      " 19  has_superstructure_stone_flag           737694 non-null  int64  \n",
      " 20  has_superstructure_cement_mortar_stone  737694 non-null  int64  \n",
      " 21  has_superstructure_mud_mortar_brick     737694 non-null  int64  \n",
      " 22  has_superstructure_cement_mortar_brick  737694 non-null  int64  \n",
      " 23  has_superstructure_timber               737694 non-null  int64  \n",
      " 24  has_superstructure_bamboo               737694 non-null  int64  \n",
      " 25  has_superstructure_rc_non_engineered    737694 non-null  int64  \n",
      " 26  has_superstructure_rc_engineered        737694 non-null  int64  \n",
      " 27  has_superstructure_other                737694 non-null  object \n",
      " 28  condition_post_eq                       737694 non-null  object \n",
      " 29  damage_grade                            737682 non-null  object \n",
      " 30  technical_solution_proposed             737681 non-null  object \n",
      "dtypes: float64(1), int64(19), object(11)\n",
      "memory usage: 174.5+ MB\n"
     ]
    }
   ],
   "source": [
    "structure_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6010e2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 762105 entries, 0 to 762104\n",
      "Data columns (total 17 columns):\n",
      " #   Column                         Non-Null Count   Dtype  \n",
      "---  ------                         --------------   -----  \n",
      " 0   building_id                    762105 non-null  float64\n",
      " 1   district_id                    762105 non-null  int64  \n",
      " 2   vdcmun_id                      762105 non-null  int64  \n",
      " 3   ward_id                        762105 non-null  int64  \n",
      " 4   legal_ownership_status         762105 non-null  object \n",
      " 5   count_families                 762103 non-null  float64\n",
      " 6   has_secondary_use              762095 non-null  float64\n",
      " 7   has_secondary_use_agriculture  762105 non-null  int64  \n",
      " 8   has_secondary_use_hotel        762105 non-null  int64  \n",
      " 9   has_secondary_use_rental       762105 non-null  int64  \n",
      " 10  has_secondary_use_institution  762105 non-null  int64  \n",
      " 11  has_secondary_use_school       762105 non-null  int64  \n",
      " 12  has_secondary_use_industry     762105 non-null  int64  \n",
      " 13  has_secondary_use_health_post  762105 non-null  int64  \n",
      " 14  has_secondary_use_gov_office   762105 non-null  int64  \n",
      " 15  has_secondary_use_use_police   762105 non-null  int64  \n",
      " 16  has_secondary_use_other        762105 non-null  int64  \n",
      "dtypes: float64(3), int64(13), object(1)\n",
      "memory usage: 98.8+ MB\n"
     ]
    }
   ],
   "source": [
    "ownership_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e93c84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 652687 entries, 0 to 652686\n",
      "Data columns (total 17 columns):\n",
      " #   Column                                 Non-Null Count   Dtype  \n",
      "---  ------                                 --------------   -----  \n",
      " 0   building_id                            652687 non-null  float64\n",
      " 1   district_id                            652687 non-null  int64  \n",
      " 2   vdcmun_id                              652687 non-null  int64  \n",
      " 3   ward_id                                652687 non-null  int64  \n",
      " 4   damage_overall_collapse                436039 non-null  object \n",
      " 5   damage_overall_leaning                 436038 non-null  object \n",
      " 6   area_assesed                           652676 non-null  object \n",
      " 7   damage_grade                           652676 non-null  object \n",
      " 8   technical_solution_proposed            652676 non-null  object \n",
      " 9   has_geotechnical_risk                  652676 non-null  float64\n",
      " 10  has_geotechnical_risk_land_settlement  652687 non-null  int64  \n",
      " 11  has_geotechnical_risk_fault_crack      652687 non-null  int64  \n",
      " 12  has_geotechnical_risk_liquefaction     652687 non-null  int64  \n",
      " 13  has_geotechnical_risk_landslide        652687 non-null  int64  \n",
      " 14  has_geotechnical_risk_rock_fall        652687 non-null  int64  \n",
      " 15  has_geotechnical_risk_flood            652687 non-null  int64  \n",
      " 16  has_geotechnical_risk_other            652687 non-null  int64  \n",
      "dtypes: float64(2), int64(10), object(5)\n",
      "memory usage: 84.7+ MB\n"
     ]
    }
   ],
   "source": [
    "damage_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e005bf20",
   "metadata": {},
   "source": [
    ">### Preliminary Dataset Prep and Feature Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a47101a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 652686 entries, 0 to 652685\n",
      "Data columns (total 49 columns):\n",
      " #   Column                                  Non-Null Count   Dtype  \n",
      "---  ------                                  --------------   -----  \n",
      " 0   count_floors_pre_eq                     652686 non-null  int64  \n",
      " 1   count_floors_post_eq                    652686 non-null  int64  \n",
      " 2   age_building                            652686 non-null  int64  \n",
      " 3   plinth_area_sq_ft                       652686 non-null  int64  \n",
      " 4   height_ft_pre_eq                        652686 non-null  int64  \n",
      " 5   land_surface_condition                  652686 non-null  object \n",
      " 6   foundation_type                         652686 non-null  object \n",
      " 7   roof_type                               652686 non-null  object \n",
      " 8   ground_floor_type                       652686 non-null  object \n",
      " 9   other_floor_type                        652686 non-null  object \n",
      " 10  position                                652685 non-null  object \n",
      " 11  plan_configuration                      652685 non-null  object \n",
      " 12  has_superstructure_adobe_mud            652686 non-null  int64  \n",
      " 13  has_superstructure_mud_mortar_stone     652686 non-null  int64  \n",
      " 14  has_superstructure_stone_flag           652686 non-null  int64  \n",
      " 15  has_superstructure_cement_mortar_stone  652686 non-null  int64  \n",
      " 16  has_superstructure_mud_mortar_brick     652686 non-null  int64  \n",
      " 17  has_superstructure_cement_mortar_brick  652686 non-null  int64  \n",
      " 18  has_superstructure_timber               652686 non-null  int64  \n",
      " 19  has_superstructure_bamboo               652686 non-null  int64  \n",
      " 20  has_superstructure_rc_non_engineered    652686 non-null  int64  \n",
      " 21  has_superstructure_rc_engineered        652686 non-null  int64  \n",
      " 22  has_superstructure_other                652686 non-null  object \n",
      " 23  damage_grade                            652675 non-null  object \n",
      " 24  legal_ownership_status                  652686 non-null  object \n",
      " 25  count_families                          652686 non-null  float64\n",
      " 26  has_secondary_use                       652677 non-null  float64\n",
      " 27  has_secondary_use_agriculture           652686 non-null  int64  \n",
      " 28  has_secondary_use_hotel                 652686 non-null  int64  \n",
      " 29  has_secondary_use_rental                652686 non-null  int64  \n",
      " 30  has_secondary_use_institution           652686 non-null  int64  \n",
      " 31  has_secondary_use_school                652686 non-null  int64  \n",
      " 32  has_secondary_use_industry              652686 non-null  int64  \n",
      " 33  has_secondary_use_health_post           652686 non-null  int64  \n",
      " 34  has_secondary_use_gov_office            652686 non-null  int64  \n",
      " 35  has_secondary_use_use_police            652686 non-null  int64  \n",
      " 36  has_secondary_use_other                 652686 non-null  int64  \n",
      " 37  damage_overall_collapse                 436039 non-null  object \n",
      " 38  damage_overall_leaning                  436038 non-null  object \n",
      " 39  area_assesed                            652675 non-null  object \n",
      " 40  technical_solution_proposed             652675 non-null  object \n",
      " 41  has_geotechnical_risk                   652675 non-null  float64\n",
      " 42  has_geotechnical_risk_land_settlement   652686 non-null  int64  \n",
      " 43  has_geotechnical_risk_fault_crack       652686 non-null  int64  \n",
      " 44  has_geotechnical_risk_liquefaction      652686 non-null  int64  \n",
      " 45  has_geotechnical_risk_landslide         652686 non-null  int64  \n",
      " 46  has_geotechnical_risk_rock_fall         652686 non-null  int64  \n",
      " 47  has_geotechnical_risk_flood             652686 non-null  int64  \n",
      " 48  has_geotechnical_risk_other             652686 non-null  int64  \n",
      "dtypes: float64(3), int64(32), object(14)\n",
      "memory usage: 249.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Eliminate features considered n/a to problem statement and hypothesis\n",
    "structure_dr = structure_df.drop(\n",
    "    columns = ['district_id', 'vdcmun_id', 'ward_id',\n",
    "               'height_ft_post_eq', 'condition_post_eq', 'technical_solution_proposed']\n",
    ")\n",
    "ownership_dr = ownership_df.drop(\n",
    "    columns = ['district_id', 'vdcmun_id', 'ward_id']\n",
    ")\n",
    "damage_dr = damage_df.drop(\n",
    "    columns=['district_id', 'vdcmun_id', 'ward_id', 'damage_grade']\n",
    ")\n",
    "\n",
    "# Merge all three dataframes into common set of label and prospective features\n",
    "temp_df = pd.merge(structure_dr, ownership_dr, how = 'inner', on = 'building_id')\n",
    "building_df = pd.merge(temp_df, damage_dr, how = 'inner', on = 'building_id')\n",
    "building_df.drop('building_id', axis = 1, inplace = True)\n",
    "building_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc60d6f8",
   "metadata": {},
   "source": [
    ">### Class Label Analysis and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8ab5192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target class (label) proportions:\n",
      "Grade 5   35.19\n",
      "Grade 4   25.15\n",
      "Grade 3   18.35\n",
      "Grade 2   11.29\n",
      "Grade 1   10.02\n",
      "NaN        0.00\n"
     ]
    }
   ],
   "source": [
    "# Identify target (y)\n",
    "target_col = 'damage_grade'\n",
    "\n",
    "# Summarize target class balance\n",
    "label_count = len(building_df)\n",
    "label_props = (building_df.groupby(target_col, dropna = False)[target_col].count() / label_count * 100).sort_values(ascending = False)\n",
    "print('Target class (label) proportions:'); print(label_props.to_string(header = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d35b604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting rows: 652686 Ending rows: 652675\n"
     ]
    }
   ],
   "source": [
    "# Drop (relatively immaterial number of) null labels\n",
    "print('Starting rows:', len(building_df), end = ' ')\n",
    "building_df.dropna(axis = 0, subset = target_col, inplace = True)\n",
    "print('Ending rows:', len(building_df))\n",
    "\n",
    "target_classes = sorted(building_df[target_col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d947147d",
   "metadata": {},
   "source": [
    ">### Data Types and Attribute Names (confirm/update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc9988b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify prospective feature columns by 'type'\n",
    "num_cols = ['age_building',\n",
    "            'plinth_area_sq_ft',\n",
    "            'height_ft_pre_eq',\n",
    "            'count_families']\n",
    "cat_cols = ['land_surface_condition',\n",
    "            'foundation_type',\n",
    "            'roof_type',\n",
    "            'ground_floor_type',\n",
    "            'other_floor_type',\n",
    "            'position',\n",
    "            'plan_configuration',\n",
    "            'legal_ownership_status',\n",
    "            'damage_overall_collapse',\n",
    "            'damage_overall_leaning',\n",
    "            'area_assesed',\n",
    "            'technical_solution_proposed']\n",
    "bin_cols = ['has_superstructure_adobe_mud',\n",
    "            'has_superstructure_mud_mortar_stone',\n",
    "            'has_superstructure_stone_flag',\n",
    "            'has_superstructure_cement_mortar_stone',\n",
    "            'has_superstructure_mud_mortar_brick',\n",
    "            'has_superstructure_cement_mortar_brick',\n",
    "            'has_superstructure_timber',\n",
    "            'has_superstructure_bamboo',\n",
    "            'has_superstructure_rc_non_engineered',\n",
    "            'has_superstructure_rc_engineered',\n",
    "            'has_superstructure_other',\n",
    "            'has_secondary_use',\n",
    "            'has_secondary_use_agriculture',\n",
    "            'has_secondary_use_hotel',\n",
    "            'has_secondary_use_rental',\n",
    "            'has_secondary_use_institution',\n",
    "            'has_secondary_use_school',\n",
    "            'has_secondary_use_industry',\n",
    "            'has_secondary_use_health_post',\n",
    "            'has_secondary_use_gov_office',\n",
    "            'has_secondary_use_use_police',\n",
    "            'has_secondary_use_other',\n",
    "            'has_geotechnical_risk',\n",
    "            'has_geotechnical_risk_land_settlement',\n",
    "            'has_geotechnical_risk_fault_crack',\n",
    "            'has_geotechnical_risk_liquefaction',\n",
    "            'has_geotechnical_risk_landslide',\n",
    "            'has_geotechnical_risk_rock_fall',\n",
    "            'has_geotechnical_risk_flood',\n",
    "            'has_geotechnical_risk_other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "649c6e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age_building           int64\n",
      "plinth_area_sq_ft      int64\n",
      "height_ft_pre_eq       int64\n",
      "count_families       float64\n",
      "land_surface_condition         object\n",
      "foundation_type                object\n",
      "roof_type                      object\n",
      "ground_floor_type              object\n",
      "other_floor_type               object\n",
      "position                       object\n",
      "plan_configuration             object\n",
      "legal_ownership_status         object\n",
      "damage_overall_collapse        object\n",
      "damage_overall_leaning         object\n",
      "area_assesed                   object\n",
      "technical_solution_proposed    object\n",
      "has_superstructure_adobe_mud                int64\n",
      "has_superstructure_mud_mortar_stone         int64\n",
      "has_superstructure_stone_flag               int64\n",
      "has_superstructure_cement_mortar_stone      int64\n",
      "has_superstructure_mud_mortar_brick         int64\n",
      "has_superstructure_cement_mortar_brick      int64\n",
      "has_superstructure_timber                   int64\n",
      "has_superstructure_bamboo                   int64\n",
      "has_superstructure_rc_non_engineered        int64\n",
      "has_superstructure_rc_engineered            int64\n",
      "has_superstructure_other                   object\n",
      "has_secondary_use                         float64\n",
      "has_secondary_use_agriculture               int64\n",
      "has_secondary_use_hotel                     int64\n",
      "has_secondary_use_rental                    int64\n",
      "has_secondary_use_institution               int64\n",
      "has_secondary_use_school                    int64\n",
      "has_secondary_use_industry                  int64\n",
      "has_secondary_use_health_post               int64\n",
      "has_secondary_use_gov_office                int64\n",
      "has_secondary_use_use_police                int64\n",
      "has_secondary_use_other                     int64\n",
      "has_geotechnical_risk                     float64\n",
      "has_geotechnical_risk_land_settlement       int64\n",
      "has_geotechnical_risk_fault_crack           int64\n",
      "has_geotechnical_risk_liquefaction          int64\n",
      "has_geotechnical_risk_landslide             int64\n",
      "has_geotechnical_risk_rock_fall             int64\n",
      "has_geotechnical_risk_flood                 int64\n",
      "has_geotechnical_risk_other                 int64\n"
     ]
    }
   ],
   "source": [
    "# Confirm [uniform] types\n",
    "print(building_df.dtypes[num_cols].to_string())\n",
    "print(building_df.dtypes[cat_cols].to_string())\n",
    "print(building_df.dtypes[bin_cols].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba2bdabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm column contents. . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c8af8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update types as needed (for consistency)\n",
    "building_df['count_families'] = building_df['count_families'].astype(int)\n",
    "building_df['has_superstructure_other'] = building_df['has_superstructure_other'].astype(int)\n",
    "building_df['has_secondary_use'] = building_df['has_secondary_use'].astype(int)\n",
    "building_df['has_geotechnical_risk'] = building_df['has_geotechnical_risk'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100b037a",
   "metadata": {},
   "source": [
    "## Data Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac302aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segregate data into predictor (X) and target (y) dataframes\n",
    "building_X = building_df.loc[:, building_df.columns != target_col].copy()\n",
    "building_y = building_df[target_col]\n",
    "\n",
    "# Partition data 70/30, stratifying for class balance (ref. above)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    building_X, building_y, test_size = 0.3, random_state = 42, stratify = building_y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d551a00",
   "metadata": {},
   "source": [
    "## Univariate Analysis and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2da5f5b",
   "metadata": {},
   "source": [
    ">### Missing/Null Values (find/impute/drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da48a69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of nulls:\n",
      "damage_overall_collapse 33.19\n",
      " damage_overall_leaning 33.19\n"
     ]
    }
   ],
   "source": [
    "na_df = pd.DataFrame(X_train[num_cols + cat_cols + bin_cols].isna().sum()) / len(X_train) * 100\n",
    "na_df.index.name = 'column'; na_df.reset_index(inplace = True)\n",
    "print('Proportion of nulls:'); print(na_df[na_df[0] > 0].to_string(index = False, header = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f9cbacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Address missing/null values here? Or, pipeline? For both train, test. . .\n",
    "X_train['damage_overall_collapse'].fillna('[missing]', inplace = True)\n",
    "X_test['damage_overall_collapse'].fillna('[missing]', inplace = True)\n",
    "\n",
    "X_train['damage_overall_leaning'].fillna('[missing]', inplace = True)\n",
    "X_test['damage_overall_leaning'].fillna('[missing]', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb2d764",
   "metadata": {},
   "source": [
    ">### Categorical Features (encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "183459ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "land_surface_condition -\n",
      "Flat (83.32)\n",
      "Steep slope (3.10)\n",
      "Moderate slope (13.58)\n",
      "\n",
      "foundation_type -\n",
      "Mud mortar-Stone/Brick (85.61)\n",
      "Bamboo/Timber (4.70)\n",
      "RC (4.01)\n",
      "Cement-Stone/Brick (5.10)\n",
      "Other (0.58)\n",
      "\n",
      "roof_type -\n",
      "Bamboo/Timber-Light roof (68.50)\n",
      "Bamboo/Timber-Heavy roof (25.74)\n",
      "RCC/RB/RBC (5.76)\n",
      "\n",
      "ground_floor_type -\n",
      "Mud (81.04)\n",
      "Brick/Stone (9.12)\n",
      "RC (9.23)\n",
      "Timber (0.46)\n",
      "Other (0.15)\n",
      "\n",
      "other_floor_type -\n",
      "Not applicable (15.59)\n",
      "Timber-Planck (15.56)\n",
      "TImber/Bamboo-Mud (64.66)\n",
      "RCC/RB/RBC (4.19)\n",
      "\n",
      "position -\n",
      "Not attached (79.07)\n",
      "Attached-1 side (17.35)\n",
      "Attached-2 side (3.43)\n",
      "Attached-3 side (0.15)\n",
      "\n",
      "plan_configuration -\n",
      "Rectangular (96.16)\n",
      "Square (2.37)\n",
      "T-shape (0.11)\n",
      "L-shape (1.10)\n",
      "Building with Central Courtyard (0.01)\n",
      "U-shape (0.05)\n",
      "Others (0.05)\n",
      "Multi-projected (0.13)\n",
      "H-shape (0.01)\n",
      "E-shape (0.02)\n",
      "\n",
      "legal_ownership_status -\n",
      "Private (96.74)\n",
      "Public (1.84)\n",
      "Institutional (1.10)\n",
      "Other (0.33)\n",
      "\n",
      "damage_overall_collapse -\n",
      "[missing] (33.19)\n",
      "Moderate-Heavy (27.74)\n",
      "None (9.12)\n",
      "Severe-Extreme (16.07)\n",
      "Insignificant/light (13.89)\n",
      "\n",
      "damage_overall_leaning -\n",
      "[missing] (33.19)\n",
      "Moderate-Heavy (11.79)\n",
      "None (31.13)\n",
      "Severe-Extreme (3.45)\n",
      "Insignificant/light (20.44)\n",
      "Nonecant/light (0.00)\n",
      "\n",
      "area_assesed -\n",
      "Building removed (19.84)\n",
      "Exterior (17.58)\n",
      "Both (59.31)\n",
      "Interior (0.32)\n",
      "Not able to inspect (2.95)\n",
      "\n",
      "technical_solution_proposed -\n",
      "Reconstruction (61.80)\n",
      "Minor repair (14.43)\n",
      "Major repair (17.43)\n",
      "No need (6.34)\n"
     ]
    }
   ],
   "source": [
    "cat_count = len(X_train)\n",
    "for cc in cat_cols:\n",
    "    print()\n",
    "    print(cc, '-')\n",
    "    for cv in pd.unique(X_train[cc]):\n",
    "        if isinstance(cv, float) != True:\n",
    "            print(cv, '(%.2f)' % (X_train[X_train[cc] == cv][cc].count() / cat_count * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aed99b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical label (y)\n",
    "label_enc = LabelEncoder().fit(y_train)\n",
    "y_train = label_enc.transform(y_train)\n",
    "y_test = label_enc.transform(y_test)\n",
    "\n",
    "# Encode other here? Or, pipeline (currently handled in pipeline)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4a4d96",
   "metadata": {},
   "source": [
    ">### Outliers (convert/drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd59a631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness:\n",
      "age_building      13.52\n",
      "plinth_area_sq_ft  3.80\n",
      "height_ft_pre_eq   1.28\n",
      "count_families     1.51\n"
     ]
    }
   ],
   "source": [
    "print('Skewness:'); print(pd.DataFrame(building_X[num_cols].skew()).to_string(header = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2317fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Address outliers here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1573d7a",
   "metadata": {},
   "source": [
    ">### Centering/Scaling (standardizing/normalizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b426df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Address centering/scaling here? Or, pipeline (currently handled in pipeline)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b970cded",
   "metadata": {},
   "source": [
    ">### \"Bad\"/Duplicate Data (find/convert/drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09664ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has_superstructure_adobe_mud              1\n",
      "has_superstructure_mud_mortar_stone       1\n",
      "has_superstructure_stone_flag             1\n",
      "has_superstructure_cement_mortar_stone    1\n",
      "has_superstructure_mud_mortar_brick       1\n",
      "has_superstructure_cement_mortar_brick    1\n",
      "has_superstructure_timber                 1\n",
      "has_superstructure_bamboo                 1\n",
      "has_superstructure_rc_non_engineered      1\n",
      "has_superstructure_rc_engineered          1\n",
      "has_superstructure_other                  1\n",
      "has_secondary_use                         1\n",
      "has_secondary_use_agriculture             1\n",
      "has_secondary_use_hotel                   1\n",
      "has_secondary_use_rental                  1\n",
      "has_secondary_use_institution             1\n",
      "has_secondary_use_school                  1\n",
      "has_secondary_use_industry                1\n",
      "has_secondary_use_health_post             1\n",
      "has_secondary_use_gov_office              1\n",
      "has_secondary_use_use_police              1\n",
      "has_secondary_use_other                   1\n",
      "has_geotechnical_risk                     1\n",
      "has_geotechnical_risk_land_settlement     1\n",
      "has_geotechnical_risk_fault_crack         1\n",
      "has_geotechnical_risk_liquefaction        1\n",
      "has_geotechnical_risk_landslide           1\n",
      "has_geotechnical_risk_rock_fall           1\n",
      "has_geotechnical_risk_flood               1\n",
      "has_geotechnical_risk_other               1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(building_X[bin_cols].max() - building_X[bin_cols].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a3cdc9",
   "metadata": {},
   "source": [
    "## Multivariate Analysis, Engineering, Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1febae04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   age_building  plinth_area_sq_ft  height_ft_pre_eq  count_families\n",
      "age_building           1.00           -0.01               0.04             0.00     \n",
      "plinth_area_sq_ft     -0.01            1.00               0.22             0.11     \n",
      "height_ft_pre_eq       0.04            0.22               1.00             0.07     \n",
      "count_families         0.00            0.11               0.07             1.00     \n"
     ]
    }
   ],
   "source": [
    "#\n",
    "corr_df = X_train[num_cols].corr()\n",
    "corr_df.rename(columns = lambda s: s[0:19], index = lambda s: s[0:19], inplace = True)\n",
    "print(corr_df)\n",
    "\n",
    "#\n",
    "# Do something like Cramer's V for categorical correlation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5480bba",
   "metadata": {},
   "source": [
    "## Modeling (iteration n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "87c0b03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardized modeling function, to create and execute a modeling pipeline through\n",
    "#   to model performance metrics\n",
    "def model(algorithm, iteration, params, classes, X_tr, y_tr, X_te, y_te, cv, plot_cm):\n",
    "    # Create transformers\n",
    "    cat_encoder = OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "    standardizer = StandardScaler()\n",
    "    \n",
    "    # Create preprocessor\n",
    "    cat_transformer = make_pipeline(cat_encoder)\n",
    "    num_transformer = make_pipeline(standardizer)\n",
    "    preprocessor = ColumnTransformer(\n",
    "        [('cat', cat_transformer, cat_cols),\n",
    "         ('num', num_transformer, num_cols)]\n",
    "    )\n",
    "\n",
    "    # Prepare algorithm with hyperparameters+\n",
    "    algorithm.set_params(**params)\n",
    "    algorithm_name = type(algorithm).__name__ + ' (iteration ' + str(iteration) + ')'\n",
    "    \n",
    "    # Create pipeline and cross-validate model (for later output)\n",
    "    pipe = make_pipeline(preprocessor, algorithm)\n",
    "    \n",
    "    # Fit model\n",
    "    print('\\n\\n', 'Fitting ' + algorithm_name + '...', end = ' ')\n",
    "    fit_start = time()\n",
    "    pipe.fit(X_tr, y_tr)\n",
    "    fit_time = time() - fit_start\n",
    "    print('done in %0.3fs.' % fit_time)\n",
    "    \n",
    "    # Cross-validate model\n",
    "    scores = []\n",
    "    cv_time = 0\n",
    "    if (cv > 0):\n",
    "        print('Cross-validating ' + algorithm_name + '...', end = ' ')\n",
    "        cv_start = time()\n",
    "        scores = cross_val_score(pipe, X_tr, y_tr, cv = cv, scoring = 'accuracy')\n",
    "        cv_time = time() - cv_start\n",
    "        print('done in %0.3fs.' % cv_time)\n",
    "        print(scores)\n",
    "    \n",
    "    # Validate model\n",
    "    print('Validating ' + algorithm_name + '...', end = ' ')\n",
    "    val_start = time()\n",
    "    y_tr_pred = pipe.predict(X_tr)\n",
    "    y_te_pred = pipe.predict(X_te)\n",
    "    val_time = time() - val_start\n",
    "    print('done in %0.2fs.' % val_time)\n",
    "\n",
    "    # Show validation results\n",
    "    if plot_cm:\n",
    "        fig, ax = plt.subplots()\n",
    "        cmd = ConfusionMatrixDisplay(confusion_matrix(y_te, y_te_pred), display_labels = classes)\n",
    "        cmd.plot(ax = ax)\n",
    "        plt.suptitle(algorithm_name, y = 1)\n",
    "        plt.title(params)\n",
    "        plt.show()\n",
    "\n",
    "    print('\\n', algorithm_name)\n",
    "    print(params)\n",
    "    print(classification_report(y_te, y_te_pred))    \n",
    "    \n",
    "    # Persist pipeline (+model)\n",
    "    pipe_filename = algorithm_name + '.pipe'\n",
    "    joblib.dump(pipe, pipe_filename)\n",
    "    \n",
    "    # Persist results\n",
    "    results = []\n",
    "    results.append ({\n",
    "        'algorithm': algorithm_name,\n",
    "        'parameters': params,\n",
    "        'fit_time': fit_time,\n",
    "        'cv_time': cv_time,\n",
    "        'val_time': val_time,\n",
    "        'scores': tuple(scores),\n",
    "        'train_acc': accuracy_score(y_tr_pred, y_tr),\n",
    "        'test_acc': accuracy_score(y_te_pred, y_te)\n",
    "    })\n",
    "    results_filename = algorithm_name + '.results'\n",
    "    joblib.dump(results, results_filename)\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "84271147",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Fitting DecisionTreeClassifier (iteration 1)... done in 1.698s.\n",
      "Validating DecisionTreeClassifier (iteration 1)... done in 1.09s.\n",
      "\n",
      " DecisionTreeClassifier (iteration 1)\n",
      "{'max_depth': 5}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.63      0.77     19623\n",
      "           1       0.66      0.84      0.74     22106\n",
      "           2       0.79      0.73      0.76     35922\n",
      "           3       0.79      0.91      0.85     49252\n",
      "           4       1.00      0.95      0.97     68900\n",
      "\n",
      "    accuracy                           0.85    195803\n",
      "   macro avg       0.85      0.81      0.82    195803\n",
      "weighted avg       0.87      0.85      0.86    195803\n",
      "\n",
      "\n",
      "\n",
      " Fitting DecisionTreeClassifier (iteration 2)... done in 1.825s.\n",
      "Validating DecisionTreeClassifier (iteration 2)... done in 1.10s.\n",
      "\n",
      " DecisionTreeClassifier (iteration 2)\n",
      "{'max_depth': 6}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.63      0.77     19623\n",
      "           1       0.66      0.85      0.74     22106\n",
      "           2       0.79      0.73      0.76     35922\n",
      "           3       0.80      0.91      0.85     49252\n",
      "           4       1.00      0.95      0.97     68900\n",
      "\n",
      "    accuracy                           0.85    195803\n",
      "   macro avg       0.85      0.81      0.82    195803\n",
      "weighted avg       0.87      0.85      0.86    195803\n",
      "\n",
      "\n",
      "\n",
      " Fitting DecisionTreeClassifier (iteration 3)... done in 1.922s.\n",
      "Validating DecisionTreeClassifier (iteration 3)... done in 1.12s.\n",
      "\n",
      " DecisionTreeClassifier (iteration 3)\n",
      "{'max_depth': 7}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80     19623\n",
      "           1       0.69      0.81      0.74     22106\n",
      "           2       0.79      0.73      0.76     35922\n",
      "           3       0.80      0.91      0.85     49252\n",
      "           4       1.00      0.95      0.97     68900\n",
      "\n",
      "    accuracy                           0.86    195803\n",
      "   macro avg       0.84      0.82      0.83    195803\n",
      "weighted avg       0.87      0.86      0.86    195803\n",
      "\n",
      "\n",
      "\n",
      " Fitting DecisionTreeClassifier (iteration 4)... done in 2.054s.\n",
      "Validating DecisionTreeClassifier (iteration 4)... done in 1.13s.\n",
      "\n",
      " DecisionTreeClassifier (iteration 4)\n",
      "{'max_depth': 8}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.72      0.81     19623\n",
      "           1       0.70      0.80      0.74     22106\n",
      "           2       0.79      0.73      0.76     35922\n",
      "           3       0.80      0.91      0.85     49252\n",
      "           4       1.00      0.95      0.97     68900\n",
      "\n",
      "    accuracy                           0.86    195803\n",
      "   macro avg       0.84      0.82      0.83    195803\n",
      "weighted avg       0.87      0.86      0.86    195803\n",
      "\n",
      "\n",
      "\n",
      " Fitting DecisionTreeClassifier (iteration 5)... done in 2.169s.\n",
      "Validating DecisionTreeClassifier (iteration 5)... done in 1.14s.\n",
      "\n",
      " DecisionTreeClassifier (iteration 5)\n",
      "{'max_depth': 9}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.71      0.81     19623\n",
      "           1       0.69      0.81      0.75     22106\n",
      "           2       0.79      0.73      0.76     35922\n",
      "           3       0.80      0.92      0.85     49252\n",
      "           4       1.00      0.95      0.97     68900\n",
      "\n",
      "    accuracy                           0.86    195803\n",
      "   macro avg       0.84      0.82      0.83    195803\n",
      "weighted avg       0.87      0.86      0.86    195803\n",
      "\n",
      "\n",
      "\n",
      " Fitting DecisionTreeClassifier (iteration 6)... done in 2.178s.\n",
      "Validating DecisionTreeClassifier (iteration 6)... done in 1.10s.\n",
      "\n",
      " DecisionTreeClassifier (iteration 6)\n",
      "{'max_depth': 10}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.72      0.81     19623\n",
      "           1       0.70      0.80      0.75     22106\n",
      "           2       0.79      0.73      0.76     35922\n",
      "           3       0.80      0.91      0.85     49252\n",
      "           4       1.00      0.95      0.97     68900\n",
      "\n",
      "    accuracy                           0.86    195803\n",
      "   macro avg       0.84      0.82      0.83    195803\n",
      "weighted avg       0.87      0.86      0.86    195803\n",
      "\n",
      "\n",
      "\n",
      " Fitting Perceptron (iteration 1)... done in 5.629s.\n",
      "Validating Perceptron (iteration 1)... done in 1.09s.\n",
      "\n",
      " Perceptron (iteration 1)\n",
      "{'class_weight': 'balanced'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.88      0.73     19623\n",
      "           1       0.62      0.40      0.49     22106\n",
      "           2       0.74      0.72      0.73     35922\n",
      "           3       0.80      0.87      0.83     49252\n",
      "           4       1.00      0.94      0.97     68900\n",
      "\n",
      "    accuracy                           0.82    195803\n",
      "   macro avg       0.76      0.76      0.75    195803\n",
      "weighted avg       0.82      0.82      0.81    195803\n",
      "\n",
      "\n",
      "\n",
      " Fitting KNeighborsClassifier (iteration 1)... done in 0.849s.\n",
      "Validating KNeighborsClassifier (iteration 1)... done in 333.99s.\n",
      "\n",
      " KNeighborsClassifier (iteration 1)\n",
      "{'n_neighbors': 3}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.78     19623\n",
      "           1       0.65      0.67      0.66     22106\n",
      "           2       0.72      0.71      0.72     35922\n",
      "           3       0.80      0.83      0.82     49252\n",
      "           4       0.98      0.95      0.97     68900\n",
      "\n",
      "    accuracy                           0.83    195803\n",
      "   macro avg       0.79      0.79      0.79    195803\n",
      "weighted avg       0.83      0.83      0.83    195803\n",
      "\n",
      "\n",
      "\n",
      " Fitting KNeighborsClassifier (iteration 2)... done in 0.844s.\n",
      "Validating KNeighborsClassifier (iteration 2)... done in 354.24s.\n",
      "\n",
      " KNeighborsClassifier (iteration 2)\n",
      "{'n_neighbors': 5}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80     19623\n",
      "           1       0.69      0.70      0.69     22106\n",
      "           2       0.75      0.73      0.74     35922\n",
      "           3       0.80      0.87      0.83     49252\n",
      "           4       0.99      0.95      0.97     68900\n",
      "\n",
      "    accuracy                           0.84    195803\n",
      "   macro avg       0.81      0.81      0.81    195803\n",
      "weighted avg       0.85      0.84      0.85    195803\n",
      "\n",
      "\n",
      "\n",
      " Fitting LogisticRegression (iteration 1)... done in 225.116s.\n",
      "Validating LogisticRegression (iteration 1)... done in 1.10s.\n",
      "\n",
      " LogisticRegression (iteration 1)\n",
      "{'solver': 'saga', 'max_iter': 400, 'multi_class': 'multinomial'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.72      0.81     19623\n",
      "           1       0.69      0.80      0.74     22106\n",
      "           2       0.78      0.73      0.76     35922\n",
      "           3       0.80      0.91      0.85     49252\n",
      "           4       1.00      0.95      0.97     68900\n",
      "\n",
      "    accuracy                           0.86    195803\n",
      "   macro avg       0.84      0.82      0.83    195803\n",
      "weighted avg       0.87      0.86      0.86    195803\n",
      "\n",
      "\n",
      "\n",
      " Fitting LinearSVC (iteration 1)... done in 122.857s.\n",
      "Validating LinearSVC (iteration 1)... done in 1.10s.\n",
      "\n",
      " LinearSVC (iteration 1)\n",
      "{'multi_class': 'crammer_singer', 'max_iter': 2000}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.63      0.77     19623\n",
      "           1       0.66      0.84      0.74     22106\n",
      "           2       0.78      0.74      0.76     35922\n",
      "           3       0.80      0.90      0.85     49252\n",
      "           4       1.00      0.95      0.97     68900\n",
      "\n",
      "    accuracy                           0.85    195803\n",
      "   macro avg       0.85      0.81      0.82    195803\n",
      "weighted avg       0.87      0.85      0.85    195803\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>parameters</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>cv_time</th>\n",
       "      <th>val_time</th>\n",
       "      <th>scores</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier (iteration 1)</td>\n",
       "      <td>{'max_depth': 5}</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0</td>\n",
       "      <td>1.09</td>\n",
       "      <td>()</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier (iteration 2)</td>\n",
       "      <td>{'max_depth': 6}</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>()</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier (iteration 3)</td>\n",
       "      <td>{'max_depth': 7}</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>()</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier (iteration 4)</td>\n",
       "      <td>{'max_depth': 8}</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1.13</td>\n",
       "      <td>()</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier (iteration 5)</td>\n",
       "      <td>{'max_depth': 9}</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0</td>\n",
       "      <td>1.14</td>\n",
       "      <td>()</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier (iteration 6)</td>\n",
       "      <td>{'max_depth': 10}</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>()</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Perceptron (iteration 1)</td>\n",
       "      <td>{'class_weight': 'balanced'}</td>\n",
       "      <td>5.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1.09</td>\n",
       "      <td>()</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier (iteration 1)</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0</td>\n",
       "      <td>333.99</td>\n",
       "      <td>()</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier (iteration 2)</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0</td>\n",
       "      <td>354.24</td>\n",
       "      <td>()</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression (iteration 1)</td>\n",
       "      <td>{'solver': 'saga', 'max_iter': 400, 'multi_cla...</td>\n",
       "      <td>225.12</td>\n",
       "      <td>0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>()</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC (iteration 1)</td>\n",
       "      <td>{'multi_class': 'crammer_singer', 'max_iter': ...</td>\n",
       "      <td>122.86</td>\n",
       "      <td>0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>()</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                algorithm                                   parameters                      fit_time  cv_time  val_time scores  train_acc  test_acc\n",
       "0  DecisionTreeClassifier (iteration 1)                                   {'max_depth': 5}     1.70      0        1.09    ()      0.85       0.85  \n",
       "0  DecisionTreeClassifier (iteration 2)                                   {'max_depth': 6}     1.82      0        1.10    ()      0.85       0.85  \n",
       "0  DecisionTreeClassifier (iteration 3)                                   {'max_depth': 7}     1.92      0        1.12    ()      0.86       0.86  \n",
       "0  DecisionTreeClassifier (iteration 4)                                   {'max_depth': 8}     2.05      0        1.13    ()      0.86       0.86  \n",
       "0  DecisionTreeClassifier (iteration 5)                                   {'max_depth': 9}     2.17      0        1.14    ()      0.86       0.86  \n",
       "0  DecisionTreeClassifier (iteration 6)                                  {'max_depth': 10}     2.18      0        1.10    ()      0.86       0.86  \n",
       "0              Perceptron (iteration 1)                       {'class_weight': 'balanced'}     5.63      0        1.09    ()      0.82       0.82  \n",
       "0    KNeighborsClassifier (iteration 1)                                 {'n_neighbors': 3}     0.85      0      333.99    ()      0.90       0.83  \n",
       "0    KNeighborsClassifier (iteration 2)                                 {'n_neighbors': 5}     0.84      0      354.24    ()      0.88       0.84  \n",
       "0      LogisticRegression (iteration 1)  {'solver': 'saga', 'max_iter': 400, 'multi_cla...   225.12      0        1.10    ()      0.86       0.86  \n",
       "0               LinearSVC (iteration 1)  {'multi_class': 'crammer_singer', 'max_iter': ...   122.86      0        1.10    ()      0.85       0.85  "
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate on models (preliminary)\n",
    "clf_results = pd.DataFrame()\n",
    "\n",
    "#\n",
    "for depth in range(5, 11):\n",
    "    tree_r = model(DecisionTreeClassifier(), (depth - 4),\n",
    "                   {'max_depth': depth},\n",
    "                   target_classes, X_train, y_train, X_test, y_test,\n",
    "                   cv = 0, plot_cm = False)\n",
    "    clf_results = pd.concat([clf_results, tree_r])\n",
    "\n",
    "#\n",
    "perc_r = model(Perceptron(), 1,\n",
    "               {'class_weight': 'balanced'},\n",
    "               target_classes, X_train, y_train, X_test, y_test,\n",
    "               cv = 0, plot_cm = False)\n",
    "clf_results = pd.concat([clf_results, perc_r])\n",
    "\n",
    "for i in range(1, 3):\n",
    "    knn_r = model(KNeighborsClassifier(), i,\n",
    "                  {'n_neighbors': 2 * i + 1},\n",
    "                  target_classes, X_train, y_train, X_test, y_test,\n",
    "                  cv = 0, plot_cm = False)\n",
    "    clf_results = pd.concat([clf_results, knn_r])\n",
    "\n",
    "logr_r = model(LogisticRegression(), 1,\n",
    "               {'solver': 'saga', 'max_iter': 400, 'multi_class': 'multinomial'},\n",
    "               target_classes, X_train, y_train, X_test, y_test,\n",
    "               cv = 0, plot_cm = False)\n",
    "clf_results = pd.concat([clf_results, logr_r])\n",
    "\n",
    "svm_r = model(LinearSVC(), 1,\n",
    "              {'multi_class': 'crammer_singer', 'max_iter': 2000},\n",
    "              target_classes, X_train, y_train, X_test, y_test,\n",
    "              cv = 0, plot_cm = False)\n",
    "clf_results = pd.concat([clf_results, svm_r])\n",
    "\n",
    "clf_results"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff47cd274c8997be5d64cba89aa887a6d1b42c6cd14acdf64f98ed7dc2146a1f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
